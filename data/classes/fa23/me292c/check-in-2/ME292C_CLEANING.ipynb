{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db1f0742-d639-4c61-be80-46537c03abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# TODO: Alex to change this function into a class; utilize OOP methods and split this into helper functions to improve future debugging\n",
    "# TODO: Alex to add unit tests for this process and validation processes (other than current 1 exception case)\n",
    "\n",
    "def cleanQualtricsData(raw, roster, question_dictionary, needsMapping=True, needsNormalization=True):\n",
    "\n",
    "    #assert all files are of .csv extension \n",
    "    #if not any([\"CSV\" in [raw.upper(), roster.upper(), question_dictionary.upper()]]):\n",
    "    #    raise Exception(\"At least one of the input files is not in CSV format\")\n",
    "    \n",
    "\n",
    "    # Imports and Instantiations\n",
    "    raw = pd.read_csv(raw)\n",
    "    question_dictionary = pd.read_csv(question_dictionary)\n",
    "    roster =  pd.read_csv(roster)\n",
    "    quantitative_questions = list(question_dictionary[question_dictionary[\"type\"] == \"quantitative\"][\"question_id\"])\n",
    "    \n",
    "    # Subset raw data to just student email, student first name, student last name, and all question responses \n",
    "    cols_needed = []\n",
    "    keywords_list = ['EMAIL', 'FIRST', 'LAST', 'Q']\n",
    "    for col in list(raw.columns):\n",
    "        if any(keyword in col.upper() for keyword in keywords_list):\n",
    "            cols_needed.append(col)\n",
    "    subset_data = raw[cols_needed]\n",
    "\n",
    "    # Replace question column names in subset data with X.Y instead of QX_Y\n",
    "    subset_data.columns = [col.replace('Q', '').replace('_', '.') for col in list(subset_data.columns)]\n",
    "\n",
    "    # Instantiate cleaned, a pointer of subset_data\n",
    "    cleaned = subset_data\n",
    "\n",
    "    # Join in TeamNumber and TeammateNumber from roster; drop rows of metadata\n",
    "    roster_email_field = [col for col in list(roster.columns) if 'EMAIL' in col.upper()][0]\n",
    "    cleaned_email_field = [col for col in list(cleaned.columns) if 'EMAIL' in col.upper()][0]\n",
    "    \n",
    "\n",
    "    full_cleaned = pd.merge(roster[[roster_email_field, 'Team Number', 'TeammateNumber']], \n",
    "                            cleaned, \n",
    "                            how=\"outer\", \n",
    "                            left_on = roster_email_field, \n",
    "                            right_on = cleaned_email_field)\n",
    "    full_cleaned = full_cleaned[~full_cleaned[\"Team Number\"].isna()]\n",
    "\n",
    "    # Sort df by TeamNumber then TeammateNumber starting from Team1\n",
    "    full_cleaned = full_cleaned.sort_values([\"Team Number\", \"TeammateNumber\"]).reset_index().drop(\"index\", axis=1)\n",
    "    \n",
    "    # If the raw data has \"Agree\"/\"Disagree\" in quantitative question columns, map these to integers 1-X where X is \"out_of\"\n",
    "    if needsMapping:\n",
    "        seven_scale_mappings = {\n",
    "            \"STRONGLY AGREE\" : 7,\n",
    "            \"AGREE\" : 6,\n",
    "            \"SOMEWHAT AGREE\" : 5,\n",
    "            \"NEITHER AGREE NOR DISAGREE\" : 4,\n",
    "            \"SOMEWHAT DISAGREE\" : 3,\n",
    "            \"DISAGREE\" : 2,\n",
    "            \"STRONGLY DISAGREE\" : 1,\n",
    "            np.nan : np.nan,\n",
    "            \"MUCH BETTER\" : 7,\n",
    "            \"MODERATELY BETTER\" : 6,\n",
    "            \"SLIGHTLY BETTER\" : 5,\n",
    "            \"ABOUT THE SAME\" : 4,\n",
    "            \"SLIGHTLY WORSE\" : 3,\n",
    "            \"MODERATELY WORSE\" : 2,\n",
    "            \"MUCH WORSE\" : 1,\n",
    "        }\n",
    "        five_scale_mappings = {\n",
    "            \"ALWAYS\" : 5,\n",
    "            \"VERY OFTEN\" : 4,\n",
    "            \"SOMETIMES\" : 3,\n",
    "            \"RARELY\" : 2,\n",
    "            \"NEVER\" : 1,\n",
    "            np.nan : np.nan\n",
    "        }\n",
    "\n",
    "        for question in quantitative_questions:\n",
    "            denominator = int(question_dictionary[question_dictionary[\"question_id\"] == question][\"out_of\"])\n",
    "            question_str = str(question)\n",
    "            \n",
    "            if question_str not in ('38.1', '38.2', '38.3', '39.1', '39.2', '39.3', '39.4'):\n",
    "                if denominator == 7:\n",
    "                    full_cleaned[question_str] = full_cleaned[question_str].str.upper()\n",
    "                    full_cleaned[question_str] = [seven_scale_mappings[response] for response in full_cleaned[question_str]]\n",
    "                if denominator == 5:\n",
    "                    full_cleaned[question_str] = full_cleaned[question_str].str.upper()\n",
    "                    full_cleaned[question_str] = [five_scale_mappings[response] for response in full_cleaned[question_str]]\n",
    "\n",
    "                # if question is quantitative but dtype is a str, change data type\n",
    "                if full_cleaned[[question_str]].dtypes[0] == str:\n",
    "                    full_cleaned[question_str] = pd.to_numeric(full_cleaned[question_str])\n",
    "        \n",
    "    # If normalization is true, then all quantitative data is normed to 0. Assumed question_dictionary includes \"out_of\" column\n",
    "    if needsNormalization:\n",
    "        for question in quantitative_questions:\n",
    "            denominator = int(question_dictionary[question_dictionary[\"question_id\"] == question][\"out_of\"])\n",
    "            question_str = str(question)\n",
    "            \n",
    "            if question not in (38.1, 38.2, 38.3, 39.1, 39.2, 39.3, 39.4):\n",
    "                if denominator == 7:\n",
    "                    full_cleaned[question_str] = (pd.to_numeric(full_cleaned[question_str]) - 4) \n",
    "                if denominator == 5:\n",
    "                    full_cleaned[question_str] = (pd.to_numeric(full_cleaned[question_str]) - 3) \n",
    "                \n",
    "    # For NA values (students that didn't complete survey, left question empty), fill in with \"No Response\"\n",
    "    full_cleaned = full_cleaned.fillna('No Response')\n",
    "    \n",
    "    return full_cleaned.to_csv(\"full_cleaned.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c42d6501-beb3-40c8-80f5-1a4763e291ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanQualtricsData('ME292C_CHECK_IN_2.csv', 'ME292C_ROSTER.csv','ME292C_QUESTION_DICTIONARY.csv', needsMapping=True,needsNormalization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb78750-4f10-4787-8ac5-c2a65056e194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
