{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db1f0742-d639-4c61-be80-46537c03abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# TODO: Alex to change this function into a class; utilize OOP methods and split this into helper functions to improve future debugging\n",
    "# TODO: Alex to add unit tests for this process and validation processes (other than current 1 exception case)\n",
    "\n",
    "def cleanQualtricsData(raw, roster, question_dictionary, needsMapping=True, needsNormalization=True):\n",
    "\n",
    "    #assert all files are of .csv extension \n",
    "    #if not any([\"CSV\" in [raw.upper(), roster.upper(), question_dictionary.upper()]]):\n",
    "    #    raise Exception(\"At least one of the input files is not in CSV format\")\n",
    "    \n",
    "\n",
    "    # Imports and Instantiations\n",
    "    raw = pd.read_csv(raw)\n",
    "    question_dictionary = pd.read_csv(question_dictionary)\n",
    "    roster =  pd.read_csv(roster)\n",
    "    quantitative_questions = list(question_dictionary[question_dictionary[\"type\"] == \"quantitative\"][\"question_id\"])\n",
    "    \n",
    "    # Subset raw data to just student email, student first name, student last name, and all question responses \n",
    "    cols_needed = []\n",
    "    keywords_list = ['EMAIL', 'FIRST', 'LAST', 'Q']\n",
    "    for col in list(raw.columns):\n",
    "        if any(keyword in col.upper() for keyword in keywords_list):\n",
    "            cols_needed.append(col)\n",
    "    subset_data = raw[cols_needed]\n",
    "\n",
    "    # Replace question column names in subset data with X.Y instead of QX_Y\n",
    "    subset_data.columns = [col.replace('Q', '').replace('_', '.') for col in list(subset_data.columns)]\n",
    "\n",
    "    # Instantiate cleaned, a pointer of subset_data\n",
    "    cleaned = subset_data\n",
    "\n",
    "    # Join in TeamNumber and TeammateNumber from roster; drop rows of metadata\n",
    "    roster_email_field = [col for col in list(roster.columns) if 'EMAIL' in col.upper()][0]\n",
    "    cleaned_email_field = [col for col in list(cleaned.columns) if 'EMAIL' in col.upper()][0]\n",
    "    \n",
    "\n",
    "    full_cleaned = pd.merge(roster[[roster_email_field, 'TeamNumber', 'TeammateNumber']], \n",
    "                            cleaned, \n",
    "                            how=\"outer\", \n",
    "                            left_on = roster_email_field, \n",
    "                            right_on = cleaned_email_field)\n",
    "    full_cleaned = full_cleaned[~full_cleaned[\"TeamNumber\"].isna()]\n",
    "\n",
    "    # Sort df by TeamNumber then TeammateNumber starting from Team1\n",
    "    full_cleaned = full_cleaned.sort_values([\"TeamNumber\", \"TeammateNumber\"]).reset_index().drop(\"index\", axis=1)\n",
    "    \n",
    "    # If the raw data has \"Agree\"/\"Disagree\" in quantitative question columns, map these to integers 1-X where X is \"out_of\"\n",
    "    if needsMapping:\n",
    "        seven_scale_mappings = {\n",
    "            \"STRONGLY AGREE\" : 7,\n",
    "            \"AGREE\" : 6,\n",
    "            \"SOMEWHAT AGREE\" : 5,\n",
    "            \"NEITHER AGREE NOR DISAGREE\" : 4,\n",
    "            \"SOMEWHAT DISAGREE\" : 3,\n",
    "            \"DISAGREE\" : 2,\n",
    "            \"STRONGLY DISAGREE\" : 1,\n",
    "            np.nan : np.nan,\n",
    "            \"MUCH BETTER\" : 7,\n",
    "            \"MODERATELY BETTER\" : 6,\n",
    "            \"SLIGHTLY BETTER\" : 5,\n",
    "            \"ABOUT THE SAME\" : 4,\n",
    "            \"SLIGHTLY WORSE\" : 3,\n",
    "            \"MODERATELY WORSE\" : 2,\n",
    "            \"MUCH WORSE\" : 1,\n",
    "        }\n",
    "        five_scale_mappings = {\n",
    "            \"ALWAYS\" : 5,\n",
    "            \"VERY OFTEN\" : 4,\n",
    "            \"SOMETIMES\" : 3,\n",
    "            \"RARELY\" : 2,\n",
    "            \"NEVER\" : 1,\n",
    "            np.nan : np.nan\n",
    "        }\n",
    "\n",
    "        for question in quantitative_questions:\n",
    "            denominator = int(question_dictionary[question_dictionary[\"question_id\"] == question][\"out_of\"])\n",
    "            question_str = str(question)\n",
    "            \n",
    "            if question_str not in ('38.1', '38.2', '38.3'):\n",
    "                if denominator == 7:\n",
    "                    full_cleaned[question_str] = full_cleaned[question_str].str.upper()\n",
    "                    full_cleaned[question_str] = [seven_scale_mappings[response] for response in full_cleaned[question_str]]\n",
    "                if denominator == 5:\n",
    "                    full_cleaned[question_str] = full_cleaned[question_str].str.upper()\n",
    "                    full_cleaned[question_str] = [five_scale_mappings[response] for response in full_cleaned[question_str]]\n",
    "\n",
    "                # if question is quantitative but dtype is a str, change data type\n",
    "                if full_cleaned[[question_str]].dtypes[0] == str:\n",
    "                    full_cleaned[question_str] = pd.to_numeric(full_cleaned[question_str])\n",
    "        \n",
    "    # If normalization is true, then all quantitative data is normed to 0. Assumed question_dictionary includes \"out_of\" column\n",
    "    if needsNormalization:\n",
    "        for question in quantitative_questions:\n",
    "            denominator = int(question_dictionary[question_dictionary[\"question_id\"] == question][\"out_of\"])\n",
    "            question_str = str(question)\n",
    "            \n",
    "            if question not in (38.1, 38.2, 38.3):\n",
    "                if denominator == 7:\n",
    "                    full_cleaned[question_str] = (pd.to_numeric(full_cleaned[question_str]) - 4) * -1\n",
    "                if denominator == 5:\n",
    "                    full_cleaned[question_str] = (pd.to_numeric(full_cleaned[question_str]) - 3) * -1\n",
    "                \n",
    "    # For NA values (students that didn't complete survey, left question empty), fill in with \"No Response\"\n",
    "    full_cleaned = full_cleaned.fillna('No Response')\n",
    "    \n",
    "    return full_cleaned.to_csv(\"full_cleaned.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b62252b7-eb75-4e2b-9043-15ecfa647d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StartDate', 'EndDate', 'Status', 'IPAddress', 'Progress',\n",
       "       'Duration (in seconds)', 'Finished', 'RecordedDate', 'ResponseId',\n",
       "       'RecipientLastName', 'RecipientFirstName', 'RecipientEmail',\n",
       "       'ExternalReference', 'LocationLatitude', 'LocationLongitude',\n",
       "       'DistributionChannel', 'UserLanguage', 'Q32', 'Q33', 'Q33_4_TEXT',\n",
       "       'Q2_1', 'Q2_2', 'Q2_3', 'Q3', 'Q4_1', 'Q4_2', 'Q4_3', 'Q4_4', 'Q5_1',\n",
       "       'Q5_2', 'Q5_3', 'Q5_4', 'Q5_5', 'Q5_7', 'Q6', 'Q7', 'Q20_1', 'Q20_2',\n",
       "       'Q20_3', 'Q20_4', 'Q20_5', 'Q20_6', 'Q20_7', 'Q20_8', 'Q20_9', 'Q20_10',\n",
       "       'Q20_11', 'Q20_12', 'Q20_13', 'Q20_14', 'Q20_15', 'Q20_16', 'Q20_17',\n",
       "       'Q20_18', 'Q20_19', 'Q20_20', 'Q21_1', 'Q21_2', 'Q21_3', 'Q14_1',\n",
       "       'Q14_2', 'Q14_3', 'Q14_4', 'Q14_5', 'Q14_6', 'Q15_1', 'Q15_2', 'Q15_3',\n",
       "       'Q15_4', 'Q15_5', 'Q15_6', 'Q16_1', 'Q16_2', 'Q16_3', 'Q16_4', 'Q16_5',\n",
       "       'Q16_6', 'Q17_1', 'Q17_2', 'Q17_3', 'Q17_4', 'Q17_5', 'Q17_6', 'Q18_1',\n",
       "       'Q18_2', 'Q18_3', 'Q18_4', 'Q18_5', 'Q18_6', 'Q19_1', 'Q19_2', 'Q19_3',\n",
       "       'Q19_4', 'Q19_5', 'Q19_6', 'Q25'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"E29_SP24_CHECKIN01_RAW_TEXT.csv\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1377e433-4087-474c-abeb-889332547a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Q5_5', 'Q5_7', 'Q14_5', 'Q14_6', 'Q15_5', 'Q15_6', 'Q16_5','Q16_6', 'Q17_5', 'Q17_6', 'Q18_5', 'Q18_6', 'Q19_5', 'Q19_6'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3db8a7c4-1074-4e2d-a235-aad0ba7427d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StartDate', 'EndDate', 'Status', 'IPAddress', 'Progress',\n",
       "       'Duration (in seconds)', 'Finished', 'RecordedDate', 'ResponseId',\n",
       "       'RecipientLastName', 'RecipientFirstName', 'RecipientEmail',\n",
       "       'ExternalReference', 'LocationLatitude', 'LocationLongitude',\n",
       "       'DistributionChannel', 'UserLanguage', 'Q32', 'Q33', 'Q33_4_TEXT',\n",
       "       'Q2_1', 'Q2_2', 'Q2_3', 'Q3', 'Q4_1', 'Q4_2', 'Q4_3', 'Q4_4', 'Q5_1',\n",
       "       'Q5_2', 'Q5_3', 'Q5_4', 'Q6', 'Q7', 'Q20_1', 'Q20_2', 'Q20_3', 'Q20_4',\n",
       "       'Q20_5', 'Q20_6', 'Q20_7', 'Q20_8', 'Q20_9', 'Q20_10', 'Q20_11',\n",
       "       'Q20_12', 'Q20_13', 'Q20_14', 'Q20_15', 'Q20_16', 'Q20_17', 'Q20_18',\n",
       "       'Q20_19', 'Q20_20', 'Q21_1', 'Q21_2', 'Q21_3', 'Q14_1', 'Q14_2',\n",
       "       'Q14_3', 'Q14_4', 'Q15_1', 'Q15_2', 'Q15_3', 'Q15_4', 'Q16_1', 'Q16_2',\n",
       "       'Q16_3', 'Q16_4', 'Q17_1', 'Q17_2', 'Q17_3', 'Q17_4', 'Q18_1', 'Q18_2',\n",
       "       'Q18_3', 'Q18_4', 'Q19_1', 'Q19_2', 'Q19_3', 'Q19_4', 'Q25'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5dd0f7d-e8e8-4417-b26a-a3994901a20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"E29_PRECLEAN_CHECKIN01_RAW_TEXT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c42d6501-beb3-40c8-80f5-1a4763e291ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanQualtricsData(\"E29_PRECLEAN_CHECKIN01_RAW_TEXT.csv\", 'E29_REVISED_LASTSORTED_ROSTER.csv','E29_QUESTION_DICTIONARY.csv', needsMapping=True,needsNormalization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb78750-4f10-4787-8ac5-c2a65056e194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
